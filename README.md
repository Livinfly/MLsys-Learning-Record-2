# MLsys Learning Record 2 - Inference Serving System

> è°ƒç ”å­¦ä¹ ç°åœ¨ä¸»æµçš„æ¨ç†æœåŠ¡ç³»ç»Ÿï¼Œæ¯”å¦‚vLLMã€SGLangç­‰ï¼ŒåŒ…æ‹¬ä»–ä»¬çš„ç³»ç»Ÿæ¡†æ¶å®ç°ï¼Œè°ƒæ•´ä¸åŒæ¨¡å‹ã€ä¸åŒåºåˆ—é•¿åº¦ç­‰åšæ€§èƒ½å¯¹æ¯”æµ‹è¯•ï¼Œæ±‡æ€»å®éªŒç»“æœ

## ç»¼è¿°ç±»

- [x] [A Survey on Efficient Inference for Large Language Models](./notes/A_Survey_on_Efficient_Inference_for_Large_Language_Models.md)
- [ ] [Towards Efficient Generative Large Language Model Serving A Survey from Algorithms to Systems](./notes/Towards_Efficient_Generative_Large_Language_Model_Serving_A_Survey_from_Algorithms_to_Systems.md)

## ç»å…¸è®ºæ–‡

- [x] Continuous Batch [Orca A Distributed Serving System for Transformer-Based Generative Models](./notes/ContinuousBatch.md)
- [x] PagedAttention vLLM [Efficient Memory Management for Large Language Model Serving with PagedAttention](./notes/PagedAttention.md)
- [x] SGLang [SGLang Efficient Execution of Structured Language Model Programs](./notes/SGLang_paper.md)
- [x] Speculative Decoding [Fast Inference from Transformers via Speculative Decoding](./notes/SpeculativeDecoding.md)
- [ ] ğŸš§[DistServe Disaggregating Prefill and Decoding for Goodput-optimized Large Language Model Serving](./notes/DistServe.md)
